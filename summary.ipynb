{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "90bdad0d-cea9-47e5-9da8-dda96796b129",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b41ae9b8-f360-4f5d-87c6-caca846288d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy.random as rnd\n",
    "import numpy.linalg as la\n",
    "import polars as pl\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "import networkx as nx\n",
    "import raphtory as rp\n",
    "import community\n",
    "import torch\n",
    "import torch_geometric as tg\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.utils.convert import from_networkx\n",
    "from torch_geometric.transforms import LargestConnectedComponents\n",
    "from torch_geometric.utils import to_networkx\n",
    "from torch_geometric.nn import Node2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "22abb4f0-1e26-49d7-9dc5-455509159103",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from datasets import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f48a8d68-5bdb-4567-b02c-fe0c8c782848",
   "metadata": {},
   "outputs": [],
   "source": [
    "import local2global as l2g\n",
    "import local2global_embedding\n",
    "from local2global import Patch\n",
    "from local2global_embedding import patches, clustering\n",
    "from local2global_embedding.network import graph, TGraph\n",
    "import local2global_embedding.patches as patches\n",
    "import induced_subgraph, anomaly_detection\n",
    "import models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f39e73e6-00bc-4054-8287-9d839d563ddd",
   "metadata": {},
   "source": [
    "## Local2Global v2 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77c7bf05-30f6-4674-823b-316b27a2a607",
   "metadata": {},
   "source": [
    "### <font color=\"grey\">  Table of Contents</font>\n",
    "\n",
    "1. #### <a href='#chapter1'>Data</a>\n",
    "2. #### <a href='#chapter2'>Embedding</a>\n",
    "3. #### <a href='#chapter3'>Alignment</a>\n",
    "4. #### <a href='#chapter4'>Anomaly detection</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af78a8e3-5886-4910-8099-cd98fa32e3d5",
   "metadata": {},
   "source": [
    "###  <a id='chapter1'> <font color=\"grey\">1. Data </font></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10d0a322-1284-4d25-bb87-1c1544608156",
   "metadata": {},
   "source": [
    "The data considered consists of temporal graphs with optional node and edge features. We should be able to efficiently load this data, as well as extract relevant graph-theoretic properties and statistics. A graph generally consists of the following:\n",
    "\n",
    "* A list of nodes\n",
    "* A list of edges\n",
    "* A list of node features\n",
    "* A list of edge features\n",
    "\n",
    "In addition, temporarl graphs consists of a sequence of graphs \n",
    "\n",
    "\n",
    "There are different ways of representing graphs:\n",
    "\n",
    "* List of edges (either as numpy array or part of polars / pandas dataframe)\n",
    "* [PyTorch Geometric](https://pytorch-geometric.readthedocs.io/en/latest/) [Data](https://pytorch-geometric.readthedocs.io/en/latest/get_started/introduction.html#data-handling-of-graphs) object\n",
    "* [Raphtory](https://www.raphtory.com/) Graph object\n",
    "* [NetworkX](https://networkx.org/) Graph object\n",
    "\n",
    "Below we give a summary of some of the important dataset we consider. Each of these datasets is stored internally as a parquet file containing a polars dataframe, with required columns 'source' and 'dest', as well as an optional column 'timestamp' for temporal graphs and additional columns representing edge features. If the graph also has node features, then an additional file with a 'node' column, an optional 'timestamp' column and columns for node features is provided. A dataloader is provided that is initialized for one of the datasets and provides interfaces for loading the data in a variety of formats, as well as providing a basic summary of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1790145e-ac39-41d5-8f52-6d974281b210",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Supported arguments: 'AS', 'elliptic', 'NFTS'\n",
    "dl = DataLoader(source='nAS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8d90cad3-73d9-4f41-be3e-248176624c5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 5)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>timestamp</th><th>nodes</th><th>nodetype</th><th>country</th><th>asname</th></tr><tr><td>datetime[μs]</td><td>str</td><td>str</td><td>str</td><td>str</td></tr></thead><tbody><tr><td>2024-09-14 00:00:00</td><td>&quot;AS7029&quot;</td><td>&quot;asn&quot;</td><td>&quot;US&quot;</td><td>&quot;WINDSTREAM&quot;</td></tr><tr><td>2024-09-14 00:00:00</td><td>&quot;AS32984&quot;</td><td>&quot;asn&quot;</td><td>&quot;US&quot;</td><td>&quot;RUELALA-INC&quot;</td></tr><tr><td>2024-09-14 00:00:00</td><td>&quot;AS136106&quot;</td><td>&quot;asn&quot;</td><td>&quot;ID&quot;</td><td>&quot;FIBERSTAR-AS-I&quot;</td></tr><tr><td>2024-09-14 00:00:00</td><td>&quot;AS58495&quot;</td><td>&quot;asn&quot;</td><td>&quot;ID&quot;</td><td>&quot;HSPNET-AS-I&quot;</td></tr><tr><td>2024-09-14 00:00:00</td><td>&quot;AS3491&quot;</td><td>&quot;asn&quot;</td><td>&quot;US&quot;</td><td>&quot;BTN-ASN&quot;</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 5)\n",
       "┌─────────────────────┬──────────┬──────────┬─────────┬────────────────┐\n",
       "│ timestamp           ┆ nodes    ┆ nodetype ┆ country ┆ asname         │\n",
       "│ ---                 ┆ ---      ┆ ---      ┆ ---     ┆ ---            │\n",
       "│ datetime[μs]        ┆ str      ┆ str      ┆ str     ┆ str            │\n",
       "╞═════════════════════╪══════════╪══════════╪═════════╪════════════════╡\n",
       "│ 2024-09-14 00:00:00 ┆ AS7029   ┆ asn      ┆ US      ┆ WINDSTREAM     │\n",
       "│ 2024-09-14 00:00:00 ┆ AS32984  ┆ asn      ┆ US      ┆ RUELALA-INC    │\n",
       "│ 2024-09-14 00:00:00 ┆ AS136106 ┆ asn      ┆ ID      ┆ FIBERSTAR-AS-I │\n",
       "│ 2024-09-14 00:00:00 ┆ AS58495  ┆ asn      ┆ ID      ┆ HSPNET-AS-I    │\n",
       "│ 2024-09-14 00:00:00 ┆ AS3491   ┆ asn      ┆ US      ┆ BTN-ASN        │\n",
       "└─────────────────────┴──────────┴──────────┴─────────┴────────────────┘"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = dl.get_nodes()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ac7bac7-7684-4567-a2f5-cdfab5992637",
   "metadata": {},
   "source": [
    "The Raphtory Graph data type is suited to temporal graphs and is the one we want to eventually use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dc3629a9-c03f-4914-833f-f950c65e717d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['nodetype', 'country', 'asname']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dl.node_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4d859a14-b044-44b8-b23b-b01ba8ae77a8",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataLoader' object has no attribute 'get_raphtory'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m rg \u001b[38;5;241m=\u001b[39m \u001b[43mdl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_raphtory\u001b[49m()\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(rg)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataLoader' object has no attribute 'get_raphtory'"
     ]
    }
   ],
   "source": [
    "rg = dl.get_raphtory()\n",
    "print(rg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c397271-1e90-46ce-86f0-fb10ce809673",
   "metadata": {},
   "source": [
    "The 'edge_list' format is sometimes used. The data is represented as a dictionary with dates as keys, and each entry simply consists of a list of edges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb290ce3-7568-44f5-b635-5b00e16b1db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "el = dl.get_edge_list()\n",
    "dt = list(el.keys())[0]\n",
    "print(dt)\n",
    "el[dt][:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79443936-0cc7-482f-83da-fbdf9fcd0296",
   "metadata": {},
   "source": [
    "With all the formats except for Raphtory, there is the option of loading the whole graph and ignoring the timestamps by supplying the 'temp=False' argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a940d488-3b87-4181-a931-11989ba0f0c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "el = dl.get_edge_list(temp=False)\n",
    "el[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "006ffe02-1273-4c99-b4dc-0c50c6ae58af",
   "metadata": {},
   "source": [
    "The 'edge_index' format is based on torch.Tensor objects and is used to initialize graphs in pytorch-geometric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41c5e5eb-32ce-4972-a13c-a117e062357d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ei = dl.get_edge_index()\n",
    "dt = list(ei.keys())[10]\n",
    "print(dt)\n",
    "ei[dt]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b53bf981-608a-4125-ab02-9b4d6b5fbab0",
   "metadata": {},
   "source": [
    "The networkx format is the format used by the common networkx package. This is a convenient format to explore graphs but it can be slow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1112a181-9aba-4c24-a843-b2bf225a37b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "gx = dl.get_networkx()\n",
    "dt = list(gx.keys())[20]\n",
    "print(gx[dt])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48fb12e3-41fb-4d2a-8761-14dba14775b9",
   "metadata": {},
   "source": [
    "Finally, there is the Data format used by pytorch-geometric, which will be used for computing the graph embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "321f4a4c-b364-4972-b031-ac49bd44c095",
   "metadata": {},
   "outputs": [],
   "source": [
    "tg = dl.get_tgeometric()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cc9b0e9-5276-4e38-b1b7-8776a5d889ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = list(tg.keys())[30]\n",
    "print(tg[dt])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc24f81b-be5d-4aac-be0b-bdc41b33b5a7",
   "metadata": {},
   "source": [
    "####  <a id='chapter11'> <font color=\"grey\">1.1 Autonomous Systems </font></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8312ffb9-b971-458e-b502-be649d32a923",
   "metadata": {},
   "source": [
    "An autonomous system (AS) is a large network or collection of networks that is managed by a single entity or organization, such as an Internet Service Provider (ISP), a university, or a corporation. AS use the [Border Gateway Protocol (BGP)](https://en.wikipedia.org/wiki/Border_Gateway_Protocol) to exchange routing information among each other. This allows them to determine the most efficient paths for data to travel across the internet.\n",
    "\n",
    "The [SNAP autonomous systems AS-733](https://snap.stanford.edu/data/as-733.html) dataset contains 733 daily snapshots that span an interval of 785 days from November 8 1997 to January 2 2000. In each of these datasets, nodes represent autonomous systems and edges indicate whether communication has taken place. The resulting graph is undirected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f04b623-3958-41d6-b457-79f08b2cf3e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dl = DataLoader(source='AS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd971d61-adbc-4896-a458-09a76d3eefc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "gx = dl.get_networkx()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eacc3b2b-53c4-4cae-bd34-233bd348ec95",
   "metadata": {},
   "outputs": [],
   "source": [
    "As = list(gx.values())[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b439eec-2c6f-4feb-8558-07bd87b78353",
   "metadata": {},
   "source": [
    "####  <a id='chapter12'> <font color=\"grey\">1.2 Elliptic Bitcoin transactions </font></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a1c0d04-2042-4e32-85a4-e7db3111fee0",
   "metadata": {},
   "source": [
    "The [Elliptic dataset](https://www.kaggle.com/datasets/ellipticco/elliptic-data-set) maps Bitcoin transactions to real entities belonging to licit categories (exchanges, wallet providers, miners, licit services, etc.) versus illicit ones (scams, malware, terrorist organizations, ransomware, Ponzi schemes, etc.). The task on the dataset is to classify the illicit and licit nodes in the graph. The graph consists of $203,769$ nodes representing transactions and $234,355$ directed edges representing payments flows.\n",
    "A case study is the paper [Anti-Money Laundering in Bitcoin: Experimenting with Graph\n",
    "Convolutional Networks for Financial Forensics](https://arxiv.org/pdf/1908.02591) by Weber et.al."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4516901c-56c1-4362-a44d-4a91f727ef70",
   "metadata": {},
   "outputs": [],
   "source": [
    "dl = DataLoader(source='elliptic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bc595e9-6742-4ac4-a5b1-4df85305a868",
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_df = dl.get_edges()\n",
    "node_df = dl.get_nodes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aac4b7c-af32-4f63-87ff-ae06694e74b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "rg = dl.get_raphtory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ad72bae-7032-4045-8094-9f331d62371e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(rg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f4e4cfc-028c-4782-8fa5-bb4e8909654d",
   "metadata": {},
   "source": [
    "Some more work needs to be done here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "217c6212-deb3-4510-bff8-26ceaeaa7df7",
   "metadata": {},
   "source": [
    "####  <a id='chapter13'> <font color=\"grey\">1.3 Ethereum NFTs </font></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c7623f8-78b6-4ac7-8dde-fc8a045cbb8f",
   "metadata": {},
   "source": [
    "The [Ethereum NFT dataset](https://www.kaggle.com/datasets/simiotic/ethereum-nfts) represents the activity of the Ethereum non-fungible token (NFT) market between April 1, 2021 and September 25, 2021. These data were collected using Moonstream.to as part of Moonstream's open data efforts. The dataset is based on on-chain NFT Transfer events as its core. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec0bf56d-df97-4fe1-bc0a-7b0e895fbbde",
   "metadata": {},
   "source": [
    "The data for this dataset still needs to be processed and the dataloader adapted."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0ad9e7f-cb2e-4aaa-ac12-9bacd377a75e",
   "metadata": {},
   "source": [
    "###  <a id='chapter2'> <font color=\"grey\">2. Embedding</font></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6cea37d-4715-405b-bf33-8fba69e6cb20",
   "metadata": {},
   "source": [
    "Graph neural networks are used to embedd the node features into a vector space, taking into account the graph structure. There are various ways of implementing these. The main method chosen here is the [Variational Graph Autoencoder](https://arxiv.org/abs/1611.07308) (VGAE). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b77ce401-d3b0-4ef5-8cd4-110a496659ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes_in_each_p=[set(list(p.nodes)) for p in As]\n",
    "nodes_in_intersection=set.intersection(*nodes_in_each_p)\n",
    "nodes_tot=[]\n",
    "for p in nodes_in_each_p:\n",
    "    nodes_tot+=p\n",
    "nodes_tot=set(nodes_tot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e77eafbd-f131-41db-9781-ddbb7dfda63f",
   "metadata": {},
   "outputs": [],
   "source": [
    "AS_patches=[from_networkx(G) for G in tqdm(As)]\n",
    "for i, p in enumerate(AS_patches):\n",
    "    p.nodes=torch.Tensor(list(As[i].nodes)).int()\n",
    "    p.num_nodes=p.nodes.size(0)\n",
    "vgae_AS_p_emb=models.VGAE_patch_embeddings(AS_patches, dim=2, hidden_dim=32, num_epochs=50, decoder=None, device='cpu', lr=0.01)\n",
    "n2v_AS_p_emb=models.Node2Vec_patch_embeddings(AS_patches, emb_dim=2 , w_length=20, c_size=10,w_per_node=10, n_negative_samples=1, p=1, q=1, num_epochs=50)\n",
    "\n",
    "vgae_AS_prob = l2g.utils.WeightedAlignmentProblem(vgae_AS_p_emb[0])  #embedding of the full graph using embeddings of each patch\n",
    "n2v_AS_prob=l2g.utils.WeightedAlignmentProblem(n2v_AS_p_emb)\n",
    "\n",
    "vgae_AS_emb=vgae_AS_prob.get_aligned_embedding()\n",
    "n2v_AS_emb=n2v_AS_prob.get_aligned_embedding()\n",
    "\n",
    "vgae_AS_outliers=set(anomaly_detection.get_outliers(vgae_AS_prob.patches, AS_patches,vgae_AS_emb[list(nodes_tot)], k=3))\n",
    "n2v_AS_outliers=set(anomaly_detection.get_outliers(n2v_AS_prob.patches, AS_patches,n2v_AS_emb[list(nodes_tot)], k=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c80403e-6b3f-4219-8e03-78d0454ecaf6",
   "metadata": {},
   "source": [
    "###  <a id='chapter3'> <font color=\"grey\">3. Patch generation and alignment</font></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e23f50c7-b315-4581-bcab-c1467f088e14",
   "metadata": {},
   "source": [
    "Describe idea."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "664f057c-334c-431b-99fe-361ba1965bf2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b86eb76e-1f8c-4165-bc23-316904164260",
   "metadata": {},
   "source": [
    "###  <a id='chapter4'> <font color=\"grey\">4. Application: anomaly detection </font></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cbb6b2a-1db5-4497-b356-c2c67c1470b4",
   "metadata": {},
   "source": [
    "Description."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "659f2fef-db57-431e-893a-64329fe53fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is code from a previous version, will have to be adjusted\n",
    "ell_outliers=[]\n",
    "for i, cc in enumerate(ell):\n",
    "    TG=TGraph(edge_index=cc.edge_index, edge_attr=cc.edge_attr,  num_nodes=cc.num_nodes, ensure_sorted=True, undir=False)\n",
    "    pt, pgraph= patches.create_patch_data(TG, partition_tensor= clustering.louvain_clustering(TG),\n",
    "                                               min_overlap=10, target_overlap=100, verbose=True)\n",
    "    patch_data = [induced_subgraph.induced_subgraph(cc, p) for p in pt]\n",
    "    for p in patch_data:\n",
    "        p.y=cc.y[p.nodes]\n",
    "        p.x=cc.x[p.nodes]\n",
    "\n",
    "    ell_p_emb=models.VGAE_patch_embeddings(patch_data, dim=2, hidden_dim=32, num_epochs=50, decoder=None, device='cpu', lr=0.01)\n",
    "\n",
    "    ell_prob = l2g.utils.WeightedAlignmentProblem(ell_p_emb[0])  #embedding of the full graph using embeddings of each patch\n",
    "    ell_emb=ell_prob.get_aligned_embedding()\n",
    "    ell_outliers.append(set(anomaly_detection.get_outliers(ell_prob.patches, patch_data,ell_emb, k=3)))\n",
    "    \n",
    "numb_ell_outliers=np.sum([len(s) for s in ell_outliers])   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d86d8b8f-b27b-48f6-83f6-4b264dc65252",
   "metadata": {},
   "outputs": [],
   "source": [
    "Nfts=Nfts[:10]\n",
    "nft_outliers=[]\n",
    "for i, cc in enumerate(Nfts):\n",
    "    TG=TGraph(edge_index=cc.edge_index, edge_attr=cc.edge_attr,  num_nodes=cc.num_nodes, ensure_sorted=True, undir=False)\n",
    "    pt, pgraph= patches.create_patch_data(TG, partition_tensor= clustering.louvain_clustering(TG),\n",
    "                                               min_overlap=10, target_overlap=100, verbose=True)\n",
    "    patch_data = [induced_subgraph.induced_subgraph(cc, p) for p in pt]\n",
    "\n",
    "    nft_p_emb=models.VGAE_patch_embeddings(patch_data, dim=2, hidden_dim=32, num_epochs=50, decoder=None, device='cpu', lr=0.01)\n",
    "    nft_prob = l2g.utils.WeightedAlignmentProblem(nft_p_emb[0])  #embedding of the full graph using embeddings of each patch\n",
    "    nft_emb=nft_prob.get_aligned_embedding()\n",
    "    nft_outliers.append(set(anomaly_detection.get_outliers(nft_prob.patches, patch_data,nft_emb, k=3)))\n",
    "    \n",
    "numb_nft_outliers=np.sum([len(s) for s in nft_outliers])   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad29927e-ebab-4bf3-9021-29a820c6c1ad",
   "metadata": {},
   "source": [
    "###  <a id='chapter5'> <font color=\"grey\">5. New algorithm </font></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "881e39ea-0f4c-4ef7-96d2-704b952cf003",
   "metadata": {},
   "source": [
    "The idea is to learn the proper alignment. The below is just playing around at the moment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6d65b51-67ed-46fe-9810-5f36399b9da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data(n_clusters, scale=1.0, std=0.5, max_size=200, min_size=10):\n",
    "    \"\"\"Generate test data with normally-distributed clusters centered on sphere.\n",
    "\n",
    "    :param int n_clusters: Number of clusters\n",
    "\n",
    "    :param float scale: Radius of sphere for cluster centers [default: 1.0]\n",
    "\n",
    "    :param float std: Standard deviation for cluster points [default: 0.5]\n",
    "\n",
    "    :param max_size: maximum cluster size [default: 200]\n",
    "\n",
    "    :param min_size: minimum cluster size [default: 10]\n",
    "    \"\"\"\n",
    "\n",
    "    \n",
    "    list_shifts = [np.array([np.cos(2 * np.pi * t / n_clusters), np.sin(2 * np.pi * t / n_clusters)]) * scale for t in range(n_clusters)]\n",
    "   \n",
    "    list_var = [std] * n_clusters\n",
    "    rg = np.random.default_rng()\n",
    "    list_sizes = [rg.integers(min_size, max_size) for _ in range(n_clusters)]\n",
    "\n",
    "    # Make union cluster\n",
    "    list_of_clusters = [rg.normal(scale=1, size=(s, 2)) * v + shift for shift, v, s in zip(list_shifts, list_var, list_sizes)]\n",
    "    points = np.vstack(list_of_clusters)\n",
    "\n",
    "    \n",
    "    return points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ff2cd5e-6403-4352-b4c5-3c42b6357ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "points = generate_data(2, scale=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e578f5a-84b2-47c2-b800-b9fd7b594947",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(points[:,0], points[:,1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00a5d00b-449a-4f4b-a897-e629085a409e",
   "metadata": {},
   "outputs": [],
   "source": [
    "G = rnd.randn(2,2)\n",
    "Q, _ = la.qr(G)\n",
    "Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6204b5c-2862-44c8-9bee-aa618062104b",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(-1,1,100).reshape(-1,1)\n",
    "y = 2*x+1\n",
    "points = np.concatenate((x,y), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff84bc27-7d42-401d-a4f5-a847d0fe44f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(points[:,0], points[:,1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cca5581-887a-475d-9ba2-aab23d6182ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "rpoints = points @ Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cd02022-7165-4f38-82c3-cd16dc9659be",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(rpoints[:,0], rpoints[:,1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40b3fdd3-ca79-497f-b6bd-3029d5308f57",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
