{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c0f84710-fa07-4ae7-a37f-f933992a5183",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fea5d599-883a-41b7-9084-a2c54697cd6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm.notebook import tqdm\n",
    "import umap.umap_ as umap\n",
    "import polars as pl\n",
    "\n",
    "import torch\n",
    "import torch_geometric as tg\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.utils import one_hot\n",
    "from torch_geometric.nn import VGAE\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "41105a8c-205f-4c34-a8d9-142290acf71a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7acfe164-880a-4aa5-8ffb-db702e78898f",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = \"../datasets/data/nas/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "148e6778-b3bc-437a-b023-db0d538c05ff",
   "metadata": {},
   "source": [
    "## Example use: New Autonomous Systems dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffc356df-39f0-4f1d-b98d-d4dcfe4665db",
   "metadata": {},
   "source": [
    "The purpose of this notebook is to walk through the graph embedding and alignment process in a self-contained way. The full existing Local2Global package is available [here](https://github.com/LJeub/Local2Global_embedding) and the expectation is to pick parts from it as a starting point. It is also available in on this repository in the Local2Global_embedding folder for reference."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e4208fd-da21-4181-ae65-1fa8c152ea2c",
   "metadata": {},
   "source": [
    "### <font color=\"grey\">  Table of Contents</font>\n",
    "\n",
    "1. #### <a href='#chapter1'>Data</a>\n",
    "2. #### <a href='#chapter2'>Embedding</a>\n",
    "3. #### <a href='#chapter3'>Visualisation</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d903eb7-22ad-4900-8720-f79d3eb44790",
   "metadata": {},
   "source": [
    "###  <a id='chapter1'> <font color=\"grey\">1. Data </font></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d25865e-21a9-4e34-bf80-125bb3d22ca5",
   "metadata": {},
   "source": [
    "The data can be accessed via the dataloader. It is saved in the datasets/data/nas directory in two parquet files. There are many alternative ways of doing this. One option to explore is to have the datasets available as in [torch_geometric datasets](https://pytorch-geometric.readthedocs.io/en/2.6.0/modules/datasets.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "38fcc940-390a-4039-aa4b-c136185c16d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dl = DataLoader(source='nAS')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dcfd3ee-0e5d-4a5e-aa09-30e0dc958132",
   "metadata": {},
   "source": [
    "The data is stored in one dataframe for the nodes (including all the features) and one for the edges (including edge weights)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9273655-0c7c-4f2f-b40a-574d38773307",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the nodes\n",
    "node_df = dl.get_nodes()\n",
    "node_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "149a77d9-d83c-45ff-a933-a774c50da54b",
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_df = dl.get_edges()\n",
    "edge_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e47ee1fa-6bd2-41ae-bd74-36d3af72bdbe",
   "metadata": {},
   "source": [
    "Ultimately, working with the people at Pometry, we want to use the [Raphtory](https://www.raphtory.com/) graph format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c87a8252-ff89-4fe2-8a37-fd4e9cb0154f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Raphtory format\n",
    "g = dl.get_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ca43c1c-c500-4597-b07e-61e751c6aa66",
   "metadata": {},
   "source": [
    "The Raphtory formal is still work in progress but one can contribute to their code (based in Rust), contribute to the discussion on their Slack (linked on their page) or directly get in touch with [Lucas Jeub](https://github.com/LJeub) and/or Ben Steer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d399ac6b-0eb2-40ea-bb32-37d6b0f0892d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Stats on the graph structure:\")\n",
    "\n",
    "number_of_nodes = g.count_nodes()\n",
    "number_of_edges = g.count_edges()\n",
    "total_interactions = g.count_temporal_edges()\n",
    "\n",
    "print(\"Number of nodes (AS nodes):\", number_of_nodes)\n",
    "print(\"Number of unique edges (src,dst):\", number_of_edges)\n",
    "print(\"Total interactions (edge updates):\", total_interactions)\n",
    "\n",
    "print(\"Stats on the graphs time range:\")\n",
    "\n",
    "earliest_datetime = g.earliest_date_time\n",
    "latest_datetime = g.latest_date_time\n",
    "\n",
    "print(\"Earliest datetime:\", earliest_datetime)\n",
    "print(\"Latest datetime:\", latest_datetime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15a91cb9-ff6a-4fcd-8fbc-aecde67fee67",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The node features are: \", g.nodes.properties.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cf8afc9-aaa4-4bfc-a99a-4dcda9795f0b",
   "metadata": {},
   "source": [
    "The graphs we are dealing are **temporal**, meaning that nodes and edges have timestamps. One can interpret this as having one graph for each point in time, with a possible overlap of nodes and edges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "994cb72f-23c6-4151-b0fd-bf4b30340a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = dl.get_dates()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "839cff93-80cf-42f4-bfe4-ed4234e88a4d",
   "metadata": {},
   "source": [
    "For this particular dataset, the graph for each day represents a patch. In order to apply graph neural networks to each patch, we need to process these into the Data format used by pytorch-geometric, described [here](https://pytorch-geometric.readthedocs.io/en/latest/get_started/introduction.html). In particular, for each patch we need to enumerate the nodes and use these indices to designate the nodes. We need a dictionary that maps the nodes in each patch to their names and we need to encode the node and edge features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1ad726d0-98c2-4e50-b173-b4a81b4e547e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode nodes present at each date\n",
    "nodes = {}\n",
    "node_dict = {}\n",
    "for d in dates:\n",
    "    nodes[d] = dl.get_node_list(ts=d)\n",
    "    node_dict[d] = dict(zip(nodes[d],range(len(nodes[d]))))\n",
    "all_nodes = dl.get_node_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b82e628b-08e8-4aa0-aa62-6b25d2c1e9b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode country codes\n",
    "cc = pl.read_csv(PATH+'country_codes.csv')\n",
    "countrycode_dict = dict(zip(cc[\"alpha-2\"].to_list(), range(cc.shape[0])))\n",
    "#cc_one_hot = one_hot(torch.tensor(list(countrycode_dict.values()), dtype=torch.int64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f9d614f4-7a6f-4b24-b743-e4591a1ec16b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign country code index to each node. The way this is done is a bit convoluted, as some nodes are assigned to both a country and to 'ZZ'\n",
    "# in the database, so we need to fix that. This should be done in pre-processing\n",
    "df = dl.get_nodes().with_columns(\n",
    "    pl.col(\"country\").replace(old=pl.Series(countrycode_dict.keys()), new=pl.Series(countrycode_dict.values())).cast(pl.Int64).alias('cc')\n",
    ").select([\"nodes\", \"cc\"]).group_by(\"nodes\").agg(pl.col(\"cc\").min().cast(pl.Int64).alias(\"cc\")).sort([\"cc\",\"nodes\"])\n",
    "node_cc_dict = dict(zip(df[\"nodes\"].to_list(), df[\"cc\"].to_list()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4f87d7aa-70de-4bdc-b54e-4ba41b655c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For every day, create a list of node features\n",
    "features = {}\n",
    "for d in dates:\n",
    "    features[d] = one_hot(torch.tensor(dl.get_nodes(ts=d).select(\n",
    "        pl.col(\"country\").replace(old=pl.Series(countrycode_dict.keys()), new=pl.Series(countrycode_dict.values())).cast(pl.Int64)\n",
    "    ).to_numpy().flatten()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1470fe0a-a8b6-4151-8e1e-2fcd210b13d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "features[dates[3]].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dccedc3-6521-4158-90bf-aba33f2d902e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create pytorch-geometric Data object\n",
    "tg_graphs = {}\n",
    "for d in tqdm(dates):\n",
    "    edges = dl.edges.filter(pl.col('timestamp')==d).select(\n",
    "        pl.col('source').replace(old=pl.Series(node_dict[d].keys()), new=pl.Series(node_dict[d].values())).cast(pl.Int64),\n",
    "        pl.col('dest').replace(old=pl.Series(node_dict[d].keys()), new=pl.Series(node_dict[d].values())).cast(pl.Int64)\n",
    "    ).to_numpy()\n",
    "    edge_index = torch.tensor([tuple(x) for x in edges], dtype=torch.long).t().contiguous()\n",
    "    tgraph = Data(edge_index=edge_index)\n",
    "    # Add features - problem is that for the embedding we only want those present at a given time\n",
    "    tgraph.x = features[d]\n",
    "    tg_graphs[d] = tgraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1f3c578c-6df9-4437-9121-ef9d1e675235",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select one date to test embedding\n",
    "data = tg_graphs[dates[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "762d7280-9de2-4f2d-8e5d-daf738cf928f",
   "metadata": {},
   "source": [
    "###  <a id='chapter2'> <font color=\"grey\">2. Embedding </font></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faab9f1c-2fd1-4f6f-bd65-8d8ce24185ab",
   "metadata": {},
   "source": [
    "For the embedding, we use the architecture of a Variational Graph Autoencoder. Given a graph $G=(V,E)$ with $|V|=n$ nodes and node features $\\mathbf{x}_i\\in \\R^d$, $i\\in [n]$, denote by $\\mathbf{X}=[\\mathbf{x}_1,\\dots,\\mathbf{x}_n]^T\\in \\R^{n\\times d}$ the features matrix and by $A=(a_{ij})\\in \\{0,1\\}^{n\\times n}$ the adjacency matrix of the graph. The **encoder** produces latent representations $\\mathbf{z}_i\\in \\R^k$ for $i\\in [n]$, which are sampled from the inference model\n",
    "\\begin{equation*}\n",
    "  q(\\mathbf{z}_i \\ | \\ \\mathbf{X},\\mathbf{A}) = \\mathcal{N}(\\mathbf{z}_i \\ | \\ \\mathbf{\\mu}_i,\\mathrm{diag}(\\mathbf{\\sigma}_i)).\n",
    "\\end{equation*}\n",
    "The means $\\mu_i$ and variances $\\mathrm{diag}(\\mathbf{\\sigma}_i)$ are parametrized using an encoder network, for example, a graph convolutional neural network (GCN). Denoting by $\\mathbf{Z}=[\\mathbf{z}_1,\\dots,\\mathbf{z}_n]^T$ the matrix of latent represenations and by $\\mathbf{\\mu}$ and $\\mathbf{\\sigma}$ the matrices representing the means and variances, we have\n",
    "\\begin{equation*}\n",
    "  \\mathbf{\\mu} = \\mathrm{GCN}_{\\mu}(\\mathbf{X},\\mathbf{A}), \\quad \\quad \\log \\mathbf{\\sigma} = \\mathrm{GCN}_{\\sigma}(\\mathbf{X},\\mathbf{A}).\n",
    "\\end{equation*}\n",
    "The **generative model** is a distribution on the adjacency matrix,\n",
    "\\begin{equation*}\n",
    "  p(\\mathbf{A}\\ | \\ \\mathbf{Z}) = \\prod_{i,j} p(a_{ij} \\ | \\ \\mathbf{z}_i,\\mathbf{z}_j).\n",
    "\\end{equation*}\n",
    "It is convenient to use\n",
    "\\begin{equation*}\n",
    "  p(a_{ij}=1 \\ | \\ \\mathbf{z}_i,\\mathbf{z}_j) = \\sigma(\\mathbf{z}_i^T\\mathbf{z}_j),\n",
    "\\end{equation*}\n",
    "where $\\sigma$ is the logistic sigmoid. In order to train the model, we optimize the evidence lower bound\n",
    "\\begin{equation*}\n",
    "  \\mathcal{L} = \\mathbf{q(\\mathbf{Z}\\ | \\ \\mathbf{X},\\mathbf{A})}[\\log p(\\mathbf{A}\\ | \\ \\mathbf{Z})]-\\mathrm{D}_{\\mathrm{KL}}(q(\\mathbf{Z}\\ | \\ \\mathbf{X},\\mathbf{A}) \\ \\| \\ p(\\mathbf{Z})).\n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "60438f44-f829-4cd8-9099-11dbda0ab78a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    Implement a Graph Convolutional Network (GCN) as encoder\n",
    "    \"\"\"\n",
    "    def __init__(self, dim, num_node_features, hidden_dim=128, cached=True, bias=True, add_self_loops=True, normalize=True):\n",
    "        super().__init__()\n",
    "        self.x_conv = tg.nn.GCNConv(num_node_features, \n",
    "                                    hidden_dim, \n",
    "                                    cached=cached, \n",
    "                                    bias=bias, \n",
    "                                    add_self_loops=add_self_loops,\n",
    "                                    normalize=normalize)\n",
    "        self.mean_conv = tg.nn.GCNConv(hidden_dim, \n",
    "                                       dim, \n",
    "                                       cached=cached,\n",
    "                                       bias=bias, \n",
    "                                       add_self_loops=add_self_loops,\n",
    "                                       normalize=normalize)\n",
    "        self.var_conv = tg.nn.GCNConv(hidden_dim, \n",
    "                                      dim, \n",
    "                                      cached=cached, \n",
    "                                      bias=bias, add_self_loops=add_self_loops,\n",
    "                                      normalize=normalize)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x = data.x\n",
    "        edge_index = data.edge_index\n",
    "\n",
    "        x = self.x_conv(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "\n",
    "        mu = self.mean_conv(x, edge_index)\n",
    "        sigma = self.var_conv(x, edge_index)\n",
    "        return mu, sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1e2060dc-6804-49eb-aa5b-0a74b568d3f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = VGAE(encoder=Encoder(64, data.num_node_features))\n",
    "#model = VGAE(encoder=VGAEconv(2, test_data.num_node_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f8bdd17a-0950-4842-bf10-198448ba843a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def VGAE_loss(model, data):\n",
    "    return model.recon_loss(model.encode(data), data.edge_index) + model.kl_loss() / data.num_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5952dc3e-2d6d-4070-8e68-09e827820147",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(data, model, loss_fun, num_epochs=100, verbose=True, lr=0.01, logger=lambda loss: None):\n",
    "    losses = []\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    # optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
    "    # schedule = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, num_epochs)\n",
    "    for e in tqdm(range(num_epochs)):\n",
    "        optimizer.zero_grad()\n",
    "        loss = loss_fun(model, data)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        losses.append(float(loss))\n",
    "        if verbose:\n",
    "            if not e % 20:\n",
    "                print(f'epoch {e}: loss={loss.item()}')\n",
    "        # schedule.step()\n",
    "    return model, losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "613527ab-a063-4283-bd62-5ee3b58121a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model, losses = train(data, model, VGAE_loss, num_epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ab6bc1b-7f0b-440e-bb1e-193136cecac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(losses)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaa00692-b04c-45fc-b44f-f8db54d5b4be",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = model.encode(data).detach().numpy()\n",
    "embedding.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "822c64b9-04a9-48c8-90b1-41bff00a7de5",
   "metadata": {},
   "source": [
    "In the original L2G code, there is a Patch class handling patches."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ad01511-5965-4676-8b56-dd304d2ec538",
   "metadata": {},
   "source": [
    "###  <a id='chapter3'> <font color=\"grey\">3. Visualisation </font></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9cd75dab-3105-454f-a615-df326670871b",
   "metadata": {},
   "outputs": [],
   "source": [
    "most_common = ['AU', 'BR', 'CN', 'DE', 'IN', 'ID', 'PL', 'RU', 'GB', 'US']\n",
    "countries = dl.get_nodes(ts=dates[0])['country'].to_list()\n",
    "indices = [i for i in range(len(countries)) if countries[i] in most_common]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4961ad0e-e22e-4160-a742-4e461bfa4741",
   "metadata": {},
   "outputs": [],
   "source": [
    "points = embedding[indices, :]\n",
    "labels = [most_common.index(countries[i]) for i in indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "24c57c17-115a-4aee-8d9f-cd69d89901e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use UMAP to visualise the graph embeddings for different days\n",
    "reducer = umap.UMAP(n_neighbors=5, min_dist=0.0, metric='euclidean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d8ede66a-8b07-4a10-8121-9645d8f5dd13",
   "metadata": {},
   "outputs": [],
   "source": [
    "#points = StandardScaler().fit_transform(points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44b68f64-9fd7-4ad5-8aad-d0939325a330",
   "metadata": {},
   "outputs": [],
   "source": [
    "umap_embedding = reducer.fit_transform(points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "159fcea7-f8e9-49d6-b371-ec3128dac17a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(12,12))\n",
    "ax.scatter(\n",
    "    umap_embedding[:, 0],\n",
    "    umap_embedding[:, 1],\n",
    "    c=[sns.color_palette()[x] for x in labels],\n",
    "    lw=1\n",
    ")\n",
    "plt.gca().set_aspect('equal', 'datalim')\n",
    "plt.title('UMAP Embedding', fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2d47bb4-4345-497e-9fdf-a0a2a0ac41c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(12,12))\n",
    "ax.scatter(\n",
    "    umap_embedding[:, 0],\n",
    "    umap_embedding[:, 1],\n",
    "    c=[sns.color_palette()[x] for x in labels],\n",
    "    lw=1\n",
    ")\n",
    "plt.gca().set_aspect('equal', 'datalim')\n",
    "plt.title('UMAP Embedding', fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7ef4871-a108-4071-8411-0ccbcfac5731",
   "metadata": {},
   "outputs": [],
   "source": [
    "#patch_list = []\n",
    "models = []\n",
    "embeddings = []\n",
    "for d in dates:\n",
    "    patch = tg_graphs[d]\n",
    "    model = VGAE(encoder=Encoder(64, patch.num_node_features))\n",
    "    model, _ = train(patch, model, VGAE_loss, num_epochs=60, lr=0.01)\n",
    "    #coordinates = model.encode(patch).detach().numpy()\n",
    "    models.append(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "0d670d22-c6cb-42b0-9f02-b188f29e5302",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_data(data, date, most_common):\n",
    "    countries = dl.get_nodes(ts=date)['country'].to_list()\n",
    "    indices = [i for i in range(len(countries)) if countries[i] in most_common]\n",
    "    points = data[indices, :]\n",
    "    labels = [most_common.index(countries[i]) for i in indices]\n",
    "    return points, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "cee98c96-b390-43d3-88ae-1a1b5f0bc10c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_plot(umap_embedding, labels, p):\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(12,12))\n",
    "    ax.scatter(\n",
    "        umap_embedding[p][:, 0],\n",
    "        umap_embedding[p][:, 1],\n",
    "        c=[sns.color_palette()[x] for x in labels[p]],\n",
    "        lw=1\n",
    "    )\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "1999cb59-72ad-4195-90fb-81de8b8bcc16",
   "metadata": {},
   "outputs": [],
   "source": [
    "reducer = umap.UMAP(n_neighbors=5, min_dist=0.0, metric='euclidean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "600815b4-92b2-4bb3-8e59-73e4201478a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = []\n",
    "for i,d in enumerate(dates):\n",
    "    patch = tg_graphs[d]\n",
    "    embeddings.append(models[i].encode(patch).detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "c861a582-44cf-407c-9984-6c2b6d5b9b71",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_umap(points, reducer):\n",
    "    return reducer.fit(points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d37a1a99-0128-4da5-8d25-81705248df4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "reducer = umap.UMAP(n_neighbors=5, min_dist=0.0, metric='euclidean')\n",
    "reducer.fit_transform(embeddings[0], dates[0], most_common)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "e7fc1254-925a-42eb-a9ae-cf8cf17b80fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "points = []\n",
    "labels = []\n",
    "umaps = []\n",
    "for i,d in enumerate(dates):\n",
    "    p, l = reduce_data(embeddings[i], d, most_common)\n",
    "    points.append(p)\n",
    "    labels.append(l)\n",
    "    umaps.append(create_umap(p, reducer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b1d8ce1-4bce-4089-ad7a-0a6974716bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(12,12))\n",
    "ax.scatter(\n",
    "    umaps[1][:, 0],\n",
    "    umaps[1][:, 1],\n",
    "    c=[sns.color_palette()[x] for x in labels[1]],\n",
    "    lw=1\n",
    ")\n",
    "plt.gca().set_aspect('equal', 'datalim')\n",
    "plt.title('UMAP Embedding', fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71c83195-a565-44f0-a1d1-f1ca34a1f4aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(4, 1, figsize=(8,20))\n",
    "for i in range(4):\n",
    "    ax[i].scatter(\n",
    "        umaps[i][:, 0],\n",
    "        umaps[i][:, 1],\n",
    "        c=[sns.color_palette()[x] for x in labels[i]],\n",
    "        lw=1\n",
    "    )\n",
    "plt.gca().set_aspect('equal', 'datalim')\n",
    "plt.title('UMAP Embedding', fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3fb79cc-708a-4766-abe4-c85ce5a33103",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
