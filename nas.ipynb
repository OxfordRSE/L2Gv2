{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c0f84710-fa07-4ae7-a37f-f933992a5183",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fea5d599-883a-41b7-9084-a2c54697cd6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy.random as rnd\n",
    "import numpy.linalg as la\n",
    "import polars as pl\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "import networkx as nx\n",
    "import raphtory as rp\n",
    "import umap\n",
    "import community\n",
    "import torch\n",
    "import torch_geometric as tg\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.utils.convert import from_networkx\n",
    "from torch_geometric.transforms import LargestConnectedComponents\n",
    "from torch_geometric.utils import to_networkx, from_networkx\n",
    "from torch_geometric.nn import Node2Vec, GCNConv, VGAE\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "41105a8c-205f-4c34-a8d9-142290acf71a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7acfe164-880a-4aa5-8ffb-db702e78898f",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = \"./datasets/data/nas/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "148e6778-b3bc-437a-b023-db0d538c05ff",
   "metadata": {},
   "source": [
    "# <font color=\"grey\"> $\\quad$ New Autonomous Systems dataset </font>\n",
    "\n",
    "$\\newcommand{\\vct}[1]{\\mathbf{#1}}$\n",
    "$\\newcommand{\\mtx}[1]{\\mathbf{#1}}$\n",
    "$\\newcommand{\\e}{\\varepsilon}$\n",
    "$\\newcommand{\\norm}[1]{\\|#1\\|}$\n",
    "$\\newcommand{\\minimize}{\\mathrm{minimize}\\quad}$\n",
    "$\\newcommand{\\maximize}{\\mathrm{maximize}\\quad}$\n",
    "$\\newcommand{\\subjto}{\\quad\\text{subject to}\\quad}$\n",
    "$\\newcommand{\\R}{\\mathbb{R}}$\n",
    "$\\newcommand{\\C}{\\mathbb{C}}$\n",
    "$\\newcommand{\\N}{\\mathbb{N}}$\n",
    "$\\newcommand{\\Z}{\\mathbb{Z}}$\n",
    "$\\newcommand{Prob}{\\mathbb{P}}$\n",
    "$\\newcommand{Expect}{\\mathbb{E}}$\n",
    "$\\newcommand{Cov}{\\mathrm{Cov}}$\n",
    "$\\newcommand{Var}{\\mathrm{Var}}$\n",
    "$\\newcommand{\\trans}{T}$\n",
    "$\\newcommand{\\ip}[2]{\\langle {#1}, {#2} \\rangle}$\n",
    "$\\newcommand{\\zerovct}{\\vct{0}}$\n",
    "$\\newcommand{\\diff}[1]{\\mathrm{d}{#1}}$\n",
    "$\\newcommand{\\conv}{\\operatorname{conv}}$\n",
    "$\\newcommand{\\inter}{{\\operatorname{int}}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e4208fd-da21-4181-ae65-1fa8c152ea2c",
   "metadata": {},
   "source": [
    "### <font color=\"grey\">  Table of Contents</font>\n",
    "\n",
    "1. #### <a href='#chapter1'>Data</a>\n",
    "2. #### <a href='#chapter2'>Embedding</a>\n",
    "3. #### <a href='#chapter3'>Visualisation</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d903eb7-22ad-4900-8720-f79d3eb44790",
   "metadata": {},
   "source": [
    "###  <a id='chapter1'> <font color=\"grey\">1. Data </font></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d25865e-21a9-4e34-bf80-125bb3d22ca5",
   "metadata": {},
   "source": [
    "The data can be accessed via the dataloader. It is saved in the datasets/data/nas directory in two parquet files. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "38fcc940-390a-4039-aa4b-c136185c16d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dl = DataLoader(source='nAS')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dcfd3ee-0e5d-4a5e-aa09-30e0dc958132",
   "metadata": {},
   "source": [
    "The data is stored in one dataframe for the nodes (including all the features) and one for the edges (including edge weights)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f9273655-0c7c-4f2f-b40a-574d38773307",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 5)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>timestamp</th><th>nodes</th><th>nodetype</th><th>country</th><th>asname</th></tr><tr><td>datetime[μs]</td><td>str</td><td>str</td><td>str</td><td>str</td></tr></thead><tbody><tr><td>2024-09-14 00:00:00</td><td>&quot;AS7029&quot;</td><td>&quot;asn&quot;</td><td>&quot;US&quot;</td><td>&quot;WINDSTREAM&quot;</td></tr><tr><td>2024-09-14 00:00:00</td><td>&quot;AS32984&quot;</td><td>&quot;asn&quot;</td><td>&quot;US&quot;</td><td>&quot;RUELALA-INC&quot;</td></tr><tr><td>2024-09-14 00:00:00</td><td>&quot;AS136106&quot;</td><td>&quot;asn&quot;</td><td>&quot;ID&quot;</td><td>&quot;FIBERSTAR-AS-I&quot;</td></tr><tr><td>2024-09-14 00:00:00</td><td>&quot;AS58495&quot;</td><td>&quot;asn&quot;</td><td>&quot;ID&quot;</td><td>&quot;HSPNET-AS-I&quot;</td></tr><tr><td>2024-09-14 00:00:00</td><td>&quot;AS3491&quot;</td><td>&quot;asn&quot;</td><td>&quot;US&quot;</td><td>&quot;BTN-ASN&quot;</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 5)\n",
       "┌─────────────────────┬──────────┬──────────┬─────────┬────────────────┐\n",
       "│ timestamp           ┆ nodes    ┆ nodetype ┆ country ┆ asname         │\n",
       "│ ---                 ┆ ---      ┆ ---      ┆ ---     ┆ ---            │\n",
       "│ datetime[μs]        ┆ str      ┆ str      ┆ str     ┆ str            │\n",
       "╞═════════════════════╪══════════╪══════════╪═════════╪════════════════╡\n",
       "│ 2024-09-14 00:00:00 ┆ AS7029   ┆ asn      ┆ US      ┆ WINDSTREAM     │\n",
       "│ 2024-09-14 00:00:00 ┆ AS32984  ┆ asn      ┆ US      ┆ RUELALA-INC    │\n",
       "│ 2024-09-14 00:00:00 ┆ AS136106 ┆ asn      ┆ ID      ┆ FIBERSTAR-AS-I │\n",
       "│ 2024-09-14 00:00:00 ┆ AS58495  ┆ asn      ┆ ID      ┆ HSPNET-AS-I    │\n",
       "│ 2024-09-14 00:00:00 ┆ AS3491   ┆ asn      ┆ US      ┆ BTN-ASN        │\n",
       "└─────────────────────┴──────────┴──────────┴─────────┴────────────────┘"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the nodes\n",
    "node_df = dl.get_nodes()\n",
    "node_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "149a77d9-d83c-45ff-a933-a774c50da54b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 4)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>timestamp</th><th>source</th><th>dest</th><th>weight</th></tr><tr><td>datetime[μs]</td><td>str</td><td>str</td><td>i64</td></tr></thead><tbody><tr><td>2024-09-14 00:00:00</td><td>&quot;AS7029&quot;</td><td>&quot;AS32984&quot;</td><td>1</td></tr><tr><td>2024-09-14 00:00:00</td><td>&quot;AS7029&quot;</td><td>&quot;AS19692&quot;</td><td>1</td></tr><tr><td>2024-09-14 00:00:00</td><td>&quot;AS7029&quot;</td><td>&quot;AS55037&quot;</td><td>1</td></tr><tr><td>2024-09-14 00:00:00</td><td>&quot;AS7029&quot;</td><td>&quot;AS1820&quot;</td><td>1</td></tr><tr><td>2024-09-14 00:00:00</td><td>&quot;AS7029&quot;</td><td>&quot;AS16265&quot;</td><td>1</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 4)\n",
       "┌─────────────────────┬────────┬─────────┬────────┐\n",
       "│ timestamp           ┆ source ┆ dest    ┆ weight │\n",
       "│ ---                 ┆ ---    ┆ ---     ┆ ---    │\n",
       "│ datetime[μs]        ┆ str    ┆ str     ┆ i64    │\n",
       "╞═════════════════════╪════════╪═════════╪════════╡\n",
       "│ 2024-09-14 00:00:00 ┆ AS7029 ┆ AS32984 ┆ 1      │\n",
       "│ 2024-09-14 00:00:00 ┆ AS7029 ┆ AS19692 ┆ 1      │\n",
       "│ 2024-09-14 00:00:00 ┆ AS7029 ┆ AS55037 ┆ 1      │\n",
       "│ 2024-09-14 00:00:00 ┆ AS7029 ┆ AS1820  ┆ 1      │\n",
       "│ 2024-09-14 00:00:00 ┆ AS7029 ┆ AS16265 ┆ 1      │\n",
       "└─────────────────────┴────────┴─────────┴────────┘"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edge_df = dl.get_edges()\n",
    "edge_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e47ee1fa-6bd2-41ae-bd74-36d3af72bdbe",
   "metadata": {},
   "source": [
    "Ultimately, working with the people at Pometry, we want to use the Raphtory graph format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c87a8252-ff89-4fe2-8a37-fd4e9cb0154f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2928235f73e481da35c3a7c15466450",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), IntProgress(value=0, max=16717484), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c716808916d949d39f834c7425564f6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), IntProgress(value=0, max=2538974), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Raphtory format\n",
    "g = dl.get_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d399ac6b-0eb2-40ea-bb32-37d6b0f0892d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stats on the graph structure:\n",
      "Number of nodes (AS nodes): 85428\n",
      "Number of unique edges (src,dst): 914346\n",
      "Total interactions (edge updates): 16717484\n",
      "Stats on the graphs time range:\n",
      "Earliest datetime: 2024-09-14 00:00:00+00:00\n",
      "Latest datetime: 2024-10-13 00:00:00+00:00\n"
     ]
    }
   ],
   "source": [
    "print(\"Stats on the graph structure:\")\n",
    "\n",
    "number_of_nodes = g.count_nodes()\n",
    "number_of_edges = g.count_edges()\n",
    "total_interactions = g.count_temporal_edges()\n",
    "\n",
    "print(\"Number of nodes (AS nodes):\", number_of_nodes)\n",
    "print(\"Number of unique edges (src,dst):\", number_of_edges)\n",
    "print(\"Total interactions (edge updates):\", total_interactions)\n",
    "\n",
    "print(\"Stats on the graphs time range:\")\n",
    "\n",
    "earliest_datetime = g.earliest_date_time\n",
    "latest_datetime = g.latest_date_time\n",
    "\n",
    "print(\"Earliest datetime:\", earliest_datetime)\n",
    "print(\"Latest datetime:\", latest_datetime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "15a91cb9-ff6a-4fcd-8fbc-aecde67fee67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The node features are:  ['asname', 'country', 'nodetype']\n"
     ]
    }
   ],
   "source": [
    "print(\"The node features are: \", g.nodes.properties.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cf8afc9-aaa4-4bfc-a99a-4dcda9795f0b",
   "metadata": {},
   "source": [
    "We need to prepare the data for the use with pytorch-geometric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "994cb72f-23c6-4151-b0fd-bf4b30340a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = dl.get_dates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8e45c71d-ac65-4fa6-a4cc-6b595c154765",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[datetime.datetime(2024, 9, 14, 0, 0),\n",
       " datetime.datetime(2024, 9, 15, 0, 0),\n",
       " datetime.datetime(2024, 9, 16, 0, 0),\n",
       " datetime.datetime(2024, 9, 17, 0, 0),\n",
       " datetime.datetime(2024, 9, 18, 0, 0),\n",
       " datetime.datetime(2024, 9, 19, 0, 0),\n",
       " datetime.datetime(2024, 9, 20, 0, 0),\n",
       " datetime.datetime(2024, 9, 21, 0, 0),\n",
       " datetime.datetime(2024, 9, 22, 0, 0),\n",
       " datetime.datetime(2024, 9, 23, 0, 0),\n",
       " datetime.datetime(2024, 9, 24, 0, 0),\n",
       " datetime.datetime(2024, 9, 25, 0, 0),\n",
       " datetime.datetime(2024, 9, 26, 0, 0),\n",
       " datetime.datetime(2024, 9, 27, 0, 0),\n",
       " datetime.datetime(2024, 9, 28, 0, 0),\n",
       " datetime.datetime(2024, 9, 29, 0, 0),\n",
       " datetime.datetime(2024, 9, 30, 0, 0),\n",
       " datetime.datetime(2024, 10, 1, 0, 0),\n",
       " datetime.datetime(2024, 10, 2, 0, 0),\n",
       " datetime.datetime(2024, 10, 3, 0, 0),\n",
       " datetime.datetime(2024, 10, 4, 0, 0),\n",
       " datetime.datetime(2024, 10, 5, 0, 0),\n",
       " datetime.datetime(2024, 10, 6, 0, 0),\n",
       " datetime.datetime(2024, 10, 7, 0, 0),\n",
       " datetime.datetime(2024, 10, 8, 0, 0),\n",
       " datetime.datetime(2024, 10, 9, 0, 0),\n",
       " datetime.datetime(2024, 10, 10, 0, 0),\n",
       " datetime.datetime(2024, 10, 11, 0, 0),\n",
       " datetime.datetime(2024, 10, 12, 0, 0),\n",
       " datetime.datetime(2024, 10, 13, 0, 0)]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1ad726d0-98c2-4e50-b173-b4a81b4e547e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode nodes\n",
    "nodes = dl.get_node_list()\n",
    "node_dict = dict(zip(nodes,range(len(nodes))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4f87d7aa-70de-4bdc-b54e-4ba41b655c6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[840],\n",
       "       [840],\n",
       "       [360],\n",
       "       ...,\n",
       "       [152],\n",
       "       [156],\n",
       "       [ 76]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Encode country codes\n",
    "cc = pl.read_csv(PATH+'country_codes.csv')\n",
    "ccdict = dict(zip(cc[\"alpha-2\"].to_list(), cc[\"country-code\"].cast(pl.Int64).to_list()))\n",
    "features = dl.nodes.select(\n",
    "    pl.col(\"country\").replace(old=pl.Series(ccdict.keys()), new=pl.Series(ccdict.values())).cast(pl.Int64)\n",
    ").to_numpy()\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3dccedc3-6521-4158-90bf-aba33f2d902e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "084660cfe96c4fb990771d64faa86e05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create pytorch-geometric Data object\n",
    "tg_graphs = {}\n",
    "for d in tqdm(dates):\n",
    "    edges = dl.edges.filter(pl.col('timestamp')==d).select(\n",
    "        pl.col('source').replace(old=pl.Series(node_dict.keys()), new=pl.Series(node_dict.values())).cast(pl.Int64),\n",
    "        pl.col('dest').replace(old=pl.Series(node_dict.keys()), new=pl.Series(node_dict.values())).cast(pl.Int64)\n",
    "    ).to_numpy()\n",
    "    edge_index = torch.tensor([tuple(x) for x in edges], dtype=torch.long).t().contiguous()\n",
    "    tgraph = Data(edge_index=edge_index)\n",
    "    # Add features - problem is that for the embedding we only want those present at a given time\n",
    "    tgraph.x = torch.from_numpy(features).float()\n",
    "    tg_graphs[d] = tgraph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d7edfd6-4b7b-422c-9458-b579869ef1fd",
   "metadata": {},
   "source": [
    "A description of how pytorch-geometric deals with its graph data structure can be found [here](https://pytorch-geometric.readthedocs.io/en/latest/get_started/introduction.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "81bfb961-b592-4ca1-aab2-f531dd713153",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2538974, 1)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1f3c578c-6df9-4437-9121-ef9d1e675235",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = tg_graphs[dates[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "762d7280-9de2-4f2d-8e5d-daf738cf928f",
   "metadata": {},
   "source": [
    "###  <a id='chapter2'> <font color=\"grey\">2. Embedding </font></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faab9f1c-2fd1-4f6f-bd65-8d8ce24185ab",
   "metadata": {},
   "source": [
    "For the embedding, we use the architecture of a Variational Graph Autoencoder. Given a graph $G=(V,E)$ with $|V|=n$ nodes and node features $\\vct{x}_i\\in \\R^d$, $i\\in [n]$, denote by $\\vct{X}=[\\vct{x}_1,\\dots,\\vct{x}_n]^T\\in \\R^{n\\times d}$ the features matrix and by $A=(a_{ij})\\in \\{0,1\\}^{n\\times n}$ the adjacency matrix of the graph. The **encoder** produces latent representations $\\vct{z}_i\\in \\R^k$ for $i\\in [n]$, which are sampled from the inference model\n",
    "\\begin{equation*}\n",
    "  q(\\vct{z}_i \\ | \\ \\vct{X},\\vct{A}) = \\mathcal{N}(\\vct{z}_i \\ | \\ \\vct{\\mu}_i,\\mathrm{diag}(\\vct{\\sigma}_i)).\n",
    "\\end{equation*}\n",
    "The means $\\mu_i$ and variances $\\mathrm{diag}(\\vct{\\sigma}_i)$ are parametrized using an encoder network, for example, a graph convolutional neural network (GCN). Denoting by $\\vct{Z}=[\\vct{z}_1,\\dots,\\vct{z}_n]^T$ the matrix of latent represenations and by $\\vct{\\mu}$ and $\\vct{\\sigma}$ the matrices representing the means and variances, we have\n",
    "\\begin{equation*}\n",
    "  \\vct{\\mu} = \\mathrm{GCN}_{\\mu}(\\vct{X},\\vct{A}), \\quad \\quad \\log \\vct{\\sigma} = \\mathrm{GCN}_{\\sigma}(\\vct{X},\\vct{A}).\n",
    "\\end{equation*}\n",
    "The **generative model** is a distribution on the adjacency matrix,\n",
    "\\begin{equation*}\n",
    "  p(\\mtx{A}\\ | \\ \\vct{Z}) = \\prod_{i,j} p(a_{ij} \\ | \\ \\vct{z}_i,\\vct{z}_j).\n",
    "\\end{equation*}\n",
    "It is convenient to use\n",
    "\\begin{equation*}\n",
    "  p(a_{ij}=1 \\ | \\ \\vct{z}_i,\\vct{z}_j) = \\sigma(\\vct{z}_i^T\\vct{z}_j),\n",
    "\\end{equation*}\n",
    "where $\\sigma$ is the logistic sigmoid. In order to train the model, we optimize the evidence lower bound\n",
    "\\begin{equation*}\n",
    "  \\mathcal{L} = \\Expect_{q(\\vct{Z}\\ | \\ \\vct{X},\\vct{A})}[\\log p(\\mtx{A}\\ | \\ \\mtx{Z})]-\\mathrm{D}_{\\mathrm{KL}}(q(\\mtx{Z}\\ | \\ \\mtx{X},\\mtx{A}) \\ \\| \\ p(\\mtx{Z})).\n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "60438f44-f829-4cd8-9099-11dbda0ab78a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    Implement a Graph Convolutional Network (GCN) as encoder\n",
    "    \"\"\"\n",
    "    def __init__(self, dim, num_node_features, hidden_dim=32, cached=True, bias=True, add_self_loops=True, normalize=True):\n",
    "        super().__init__()\n",
    "        self.x_conv = tg.nn.GCNConv(num_node_features, \n",
    "                                    hidden_dim, \n",
    "                                    cached=cached, \n",
    "                                    bias=bias, \n",
    "                                    add_self_loops=add_self_loops,\n",
    "                                    normalize=normalize)\n",
    "        self.mean_conv = tg.nn.GCNConv(hidden_dim, \n",
    "                                       dim, \n",
    "                                       cached=cached,\n",
    "                                       bias=bias, \n",
    "                                       add_self_loops=add_self_loops,\n",
    "                                       normalize=normalize)\n",
    "        self.var_conv = tg.nn.GCNConv(hidden_dim, \n",
    "                                      dim, \n",
    "                                      cached=cached, \n",
    "                                      bias=bias, add_self_loops=add_self_loops,\n",
    "                                      normalize=normalize)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x = data.x\n",
    "        edge_index = data.edge_index\n",
    "\n",
    "        x = self.x_conv(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "\n",
    "        mu = self.mean_conv(x, edge_index)\n",
    "        sigma = self.var_conv(x, edge_index)\n",
    "        return mu, sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1e2060dc-6804-49eb-aa5b-0a74b568d3f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = VGAE(encoder=Encoder(10, data.num_node_features))\n",
    "#model = VGAE(encoder=VGAEconv(2, test_data.num_node_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f8bdd17a-0950-4842-bf10-198448ba843a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def VGAE_loss(model, data):\n",
    "    return model.recon_loss(model.encode(data), data.edge_index) + model.kl_loss() / data.num_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5952dc3e-2d6d-4070-8e68-09e827820147",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(data, model, loss_fun, num_epochs=100, verbose=True, lr=0.01, logger=lambda loss: None):\n",
    "    losses = []\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    # optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
    "    # schedule = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, num_epochs)\n",
    "    for e in tqdm(range(num_epochs)):\n",
    "        optimizer.zero_grad()\n",
    "        loss = loss_fun(model, data)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        losses.append(float(loss))\n",
    "        if verbose:\n",
    "            if not e % 20:\n",
    "                print(f'epoch {e}: loss={loss.item()}')\n",
    "        # schedule.step()\n",
    "    return model, losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "613527ab-a063-4283-bd62-5ee3b58121a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4a86c486e944bdca86b0ea038a13e3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0: loss=33.53376770019531\n",
      "epoch 20: loss=33.47657012939453\n",
      "epoch 40: loss=33.478885650634766\n",
      "epoch 60: loss=33.48881530761719\n",
      "epoch 80: loss=33.47344207763672\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "cannot unpack non-iterable VGAE object",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[40], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model, losses \u001b[38;5;241m=\u001b[39m train(data, model, VGAE_loss, num_epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: cannot unpack non-iterable VGAE object"
     ]
    }
   ],
   "source": [
    "model, losses = train(data, model, VGAE_loss, num_epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ab6bc1b-7f0b-440e-bb1e-193136cecac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(losses)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaa00692-b04c-45fc-b44f-f8db54d5b4be",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = model.encode(data).detach().numpy()\n",
    "embedding.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd78c888-0043-43be-88b7-4f5ce49e77f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def VGAE_patch_embeddings(patch_data, dim=2, hidden_dim=32, num_epochs=100, decoder=None, device='cpu', lr=0.01):\n",
    "    patch_list = []\n",
    "    models = []\n",
    "    for patch in patch_data:\n",
    "        if patch.x is None:\n",
    "            patch.x = speye(patch.num_nodes)\n",
    "            print(f\"training patch with {patch.edge_index.shape[1]} edges\")   #added [i] to every patch\n",
    "            model = tg.nn.VGAE(encoder=VGAEconv(dim, patch.x.shape[1], hidden_dim=hidden_dim), decoder=decoder).to(device)\n",
    "            patch.to(device)\n",
    "\n",
    "        model = train(patch, model, VGAE_loss, num_epochs=num_epochs, lr=lr)\n",
    "        with torch.no_grad():\n",
    "            model.eval()\n",
    "            coordinates = model.encode(patch).to('cpu').numpy()\n",
    "            models.append(model)\n",
    "            patch_list.append(l2g.Patch(patch.nodes.to('cpu').numpy(), coordinates))\n",
    "    return patch_list, models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ad01511-5965-4676-8b56-dd304d2ec538",
   "metadata": {},
   "source": [
    "###  <a id='chapter3'> <font color=\"grey\">3. Visualisation </font></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24c57c17-115a-4aee-8d9f-cd69d89901e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use UMAP to visualise the graph embeddings for different days\n",
    "reducer = umap.UMAP()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44b68f64-9fd7-4ad5-8aad-d0939325a330",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "159fcea7-f8e9-49d6-b371-ec3128dac17a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
