{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "c0f84710-fa07-4ae7-a37f-f933992a5183",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "fea5d599-883a-41b7-9084-a2c54697cd6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy.random as rnd\n",
    "import numpy.linalg as la\n",
    "import polars as pl\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "import networkx as nx\n",
    "import raphtory as rp\n",
    "import umap\n",
    "import community\n",
    "import torch\n",
    "import torch_geometric as tg\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.utils.convert import from_networkx\n",
    "from torch_geometric.transforms import LargestConnectedComponents\n",
    "from torch_geometric.utils import to_networkx, from_networkx\n",
    "from torch_geometric.nn import Node2Vec, GCNConv, VGAE\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "41105a8c-205f-4c34-a8d9-142290acf71a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "148e6778-b3bc-437a-b023-db0d538c05ff",
   "metadata": {},
   "source": [
    "# <font color=\"grey\"> $\\quad$ New Autonomous Systems dataset </font>\n",
    "\n",
    "$\\newcommand{\\vct}[1]{\\mathbf{#1}}$\n",
    "$\\newcommand{\\mtx}[1]{\\mathbf{#1}}$\n",
    "$\\newcommand{\\e}{\\varepsilon}$\n",
    "$\\newcommand{\\norm}[1]{\\|#1\\|}$\n",
    "$\\newcommand{\\minimize}{\\mathrm{minimize}\\quad}$\n",
    "$\\newcommand{\\maximize}{\\mathrm{maximize}\\quad}$\n",
    "$\\newcommand{\\subjto}{\\quad\\text{subject to}\\quad}$\n",
    "$\\newcommand{\\R}{\\mathbb{R}}$\n",
    "$\\newcommand{\\C}{\\mathbb{C}}$\n",
    "$\\newcommand{\\N}{\\mathbb{N}}$\n",
    "$\\newcommand{\\Z}{\\mathbb{Z}}$\n",
    "$\\newcommand{Prob}{\\mathbb{P}}$\n",
    "$\\newcommand{Expect}{\\mathbb{E}}$\n",
    "$\\newcommand{Cov}{\\mathrm{Cov}}$\n",
    "$\\newcommand{Var}{\\mathrm{Var}}$\n",
    "$\\newcommand{\\trans}{T}$\n",
    "$\\newcommand{\\ip}[2]{\\langle {#1}, {#2} \\rangle}$\n",
    "$\\newcommand{\\zerovct}{\\vct{0}}$\n",
    "$\\newcommand{\\diff}[1]{\\mathrm{d}{#1}}$\n",
    "$\\newcommand{\\conv}{\\operatorname{conv}}$\n",
    "$\\newcommand{\\inter}{{\\operatorname{int}}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e4208fd-da21-4181-ae65-1fa8c152ea2c",
   "metadata": {},
   "source": [
    "### <font color=\"grey\">  Table of Contents</font>\n",
    "\n",
    "1. #### <a href='#chapter1'>Data</a>\n",
    "2. #### <a href='#chapter2'>Embedding</a>\n",
    "3. #### <a href='#chapter3'>Visualisation</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d903eb7-22ad-4900-8720-f79d3eb44790",
   "metadata": {},
   "source": [
    "###  <a id='chapter1'> <font color=\"grey\">1. Data </font></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d25865e-21a9-4e34-bf80-125bb3d22ca5",
   "metadata": {},
   "source": [
    "The data can be accessed via the dataloader. It is saved in the datasets/data/nas directory in two parquet files. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "38fcc940-390a-4039-aa4b-c136185c16d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dl = DataLoader(source='nAS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "c491df93-835c-46e8-8d93-f8bdc69bd9d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 4)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>timestamp</th><th>source</th><th>dest</th><th>weight</th></tr><tr><td>datetime[μs]</td><td>i64</td><td>i64</td><td>i64</td></tr></thead><tbody><tr><td>2024-09-29 00:00:00</td><td>8151</td><td>1840</td><td>1</td></tr><tr><td>2024-09-29 00:00:00</td><td>8151</td><td>10420</td><td>1</td></tr><tr><td>2024-09-29 00:00:00</td><td>8151</td><td>136907</td><td>1</td></tr><tr><td>2024-09-29 00:00:00</td><td>8151</td><td>7173</td><td>1</td></tr><tr><td>2024-09-29 00:00:00</td><td>8151</td><td>28391</td><td>1</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 4)\n",
       "┌─────────────────────┬────────┬────────┬────────┐\n",
       "│ timestamp           ┆ source ┆ dest   ┆ weight │\n",
       "│ ---                 ┆ ---    ┆ ---    ┆ ---    │\n",
       "│ datetime[μs]        ┆ i64    ┆ i64    ┆ i64    │\n",
       "╞═════════════════════╪════════╪════════╪════════╡\n",
       "│ 2024-09-29 00:00:00 ┆ 8151   ┆ 1840   ┆ 1      │\n",
       "│ 2024-09-29 00:00:00 ┆ 8151   ┆ 10420  ┆ 1      │\n",
       "│ 2024-09-29 00:00:00 ┆ 8151   ┆ 136907 ┆ 1      │\n",
       "│ 2024-09-29 00:00:00 ┆ 8151   ┆ 7173   ┆ 1      │\n",
       "│ 2024-09-29 00:00:00 ┆ 8151   ┆ 28391  ┆ 1      │\n",
       "└─────────────────────┴────────┴────────┴────────┘"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the edges\n",
    "edge_df = dl.get_edges()\n",
    "edge_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dcfd3ee-0e5d-4a5e-aa09-30e0dc958132",
   "metadata": {},
   "source": [
    "The weight columns has no relevance, it is always 1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "f9273655-0c7c-4f2f-b40a-574d38773307",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 3)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>timestamp</th><th>nodes</th><th>country_code</th></tr><tr><td>datetime[μs]</td><td>i64</td><td>i64</td></tr></thead><tbody><tr><td>2024-09-29 00:00:00</td><td>8151</td><td>150</td></tr><tr><td>2024-09-29 00:00:00</td><td>1840</td><td>150</td></tr><tr><td>2024-09-29 00:00:00</td><td>25220</td><td>52</td></tr><tr><td>2024-09-29 00:00:00</td><td>198570</td><td>52</td></tr><tr><td>2024-09-29 00:00:00</td><td>4657</td><td>191</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 3)\n",
       "┌─────────────────────┬────────┬──────────────┐\n",
       "│ timestamp           ┆ nodes  ┆ country_code │\n",
       "│ ---                 ┆ ---    ┆ ---          │\n",
       "│ datetime[μs]        ┆ i64    ┆ i64          │\n",
       "╞═════════════════════╪════════╪══════════════╡\n",
       "│ 2024-09-29 00:00:00 ┆ 8151   ┆ 150          │\n",
       "│ 2024-09-29 00:00:00 ┆ 1840   ┆ 150          │\n",
       "│ 2024-09-29 00:00:00 ┆ 25220  ┆ 52           │\n",
       "│ 2024-09-29 00:00:00 ┆ 198570 ┆ 52           │\n",
       "│ 2024-09-29 00:00:00 ┆ 4657   ┆ 191          │\n",
       "└─────────────────────┴────────┴──────────────┘"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the nodes\n",
    "node_df = dl.get_nodes()\n",
    "node_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "a660f2b3-99b7-48ff-8a19-f9b7897f5b83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "85069"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nodes = node_df['nodes'].unique().to_numpy()\n",
    "len(nodes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e5318d4-1d82-446d-bbf4-394fa8bc7bca",
   "metadata": {},
   "source": [
    "The nodes have one feature: the country. This can be used to label and identify different subgraphs. In order to identify the features with a country, there is the country_code file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "a0b07487-b077-4745-9e3d-a7f4d3dbc580",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (2, 2)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>index</th><th>country</th></tr><tr><td>i64</td><td>str</td></tr></thead><tbody><tr><td>0</td><td>&quot;AD&quot;</td></tr><tr><td>1</td><td>&quot;AE&quot;</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (2, 2)\n",
       "┌───────┬─────────┐\n",
       "│ index ┆ country │\n",
       "│ ---   ┆ ---     │\n",
       "│ i64   ┆ str     │\n",
       "╞═══════╪═════════╡\n",
       "│ 0     ┆ AD      │\n",
       "│ 1     ┆ AE      │\n",
       "└───────┴─────────┘"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "country_codes = pl.read_parquet('./datasets/data/nas/country_codes.parquet')\n",
    "country_codes[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "91a2cb7e-16cc-4677-ab4b-1950b1f7feea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime(2024, 9, 29, 0, 0)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The timestamp column consists of datetime objects\n",
    "date = node_df['timestamp'][0]\n",
    "date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "637fd1ef-42c1-47e8-ba1e-3c40655f6c70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[datetime.datetime(2024, 9, 29, 0, 0),\n",
       " datetime.datetime(2024, 9, 30, 0, 0),\n",
       " datetime.datetime(2024, 10, 1, 0, 0),\n",
       " datetime.datetime(2024, 10, 2, 0, 0),\n",
       " datetime.datetime(2024, 10, 3, 0, 0),\n",
       " datetime.datetime(2024, 10, 4, 0, 0),\n",
       " datetime.datetime(2024, 10, 5, 0, 0),\n",
       " datetime.datetime(2024, 10, 6, 0, 0),\n",
       " datetime.datetime(2024, 10, 7, 0, 0),\n",
       " datetime.datetime(2024, 10, 8, 0, 0),\n",
       " datetime.datetime(2024, 10, 9, 0, 0),\n",
       " datetime.datetime(2024, 10, 10, 0, 0),\n",
       " datetime.datetime(2024, 10, 11, 0, 0),\n",
       " datetime.datetime(2024, 10, 12, 0, 0),\n",
       " datetime.datetime(2024, 10, 13, 0, 0)]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dates = dl.get_dates()\n",
    "dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "5452d1db-b5d6-4dde-96ac-ca29d4d4406b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 15/15 [00:04<00:00,  3.65it/s]\n"
     ]
    }
   ],
   "source": [
    "# Finally, we can also get a graph in the torch-geometric format, which is useful for graph neural networks\n",
    "data = dl.get_tgeometric()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62cf193b-44ed-4659-b101-dd20151e09b7",
   "metadata": {},
   "source": [
    "There may be a bug in this feature, will check later"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d7edfd6-4b7b-422c-9458-b579869ef1fd",
   "metadata": {},
   "source": [
    "A description of how pytorch-geometric deals with its graph data structure can be found [here](https://pytorch-geometric.readthedocs.io/en/latest/get_started/introduction.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "1f3c578c-6df9-4437-9121-ef9d1e675235",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[dates[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "4b5f81e4-8f3d-40f2-ba1e-c97dc1587a8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  8151,   8151,   8151,  ..., 142340, 152037, 152037],\n",
       "        [  1840,  10420, 136907,  ..., 142340, 152037, 150476]])"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show the edges\n",
    "data.edge_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "bab41cc2-7b7f-47a5-8c82-e9bac7c69494",
   "metadata": {},
   "outputs": [],
   "source": [
    "def speye(n, dtype=torch.float):\n",
    "    \"\"\"identity matrix of dimension n as sparse_coo_tensor.\"\"\"\n",
    "    return torch.sparse_coo_tensor(torch.tile(torch.arange(n, dtype=torch.long), (2, 1)),\n",
    "                                   torch.ones(n, dtype=dtype),\n",
    "                                   (n, n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "07a3e793-a8e3-4d47-9bff-8850d17b5868",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use empty features\n",
    "# Use this as features in the absence of features\n",
    "data.x = speye(len(nodes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "83a218e0-d077-4e7a-9981-1cd63d31db2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "85069"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.num_node_features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "762d7280-9de2-4f2d-8e5d-daf738cf928f",
   "metadata": {},
   "source": [
    "###  <a id='chapter2'> <font color=\"grey\">2. Embedding </font></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faab9f1c-2fd1-4f6f-bd65-8d8ce24185ab",
   "metadata": {},
   "source": [
    "For the embedding, we use the architecture of a Variational Graph Autoencoder. Given a graph $G=(V,E)$ with $|V|=n$ nodes and node features $\\vct{x}_i\\in \\R^d$, $i\\in [n]$, denote by $\\vct{X}=[\\vct{x}_1,\\dots,\\vct{x}_n]^T\\in \\R^{n\\times d}$ the features matrix and by $A=(a_{ij})\\in \\{0,1\\}^{n\\times n}$ the adjacency matrix of the graph. The **encoder** produces latent representations $\\vct{z}_i\\in \\R^k$ for $i\\in [n]$, which are sampled from the inference model\n",
    "\\begin{equation*}\n",
    "  q(\\vct{z}_i \\ | \\ \\vct{X},\\vct{A}) = \\mathcal{N}(\\vct{z}_i \\ | \\ \\vct{\\mu}_i,\\mathrm{diag}(\\vct{\\sigma}_i)).\n",
    "\\end{equation*}\n",
    "The means $\\mu_i$ and variances $\\mathrm{diag}(\\vct{\\sigma}_i)$ are parametrized using an encoder network, for example, a graph convolutional neural network (GCN). Denoting by $\\vct{Z}=[\\vct{z}_1,\\dots,\\vct{z}_n]^T$ the matrix of latent represenations and by $\\vct{\\mu}$ and $\\vct{\\sigma}$ the matrices representing the means and variances, we have\n",
    "\\begin{equation*}\n",
    "  \\vct{\\mu} = \\mathrm{GCN}_{\\mu}(\\vct{X},\\vct{A}), \\quad \\quad \\log \\vct{\\sigma} = \\mathrm{GCN}_{\\sigma}(\\vct{X},\\vct{A}).\n",
    "\\end{equation*}\n",
    "The **generative model** is a distribution on the adjacency matrix,\n",
    "\\begin{equation*}\n",
    "  p(\\mtx{A}\\ | \\ \\vct{Z}) = \\prod_{i,j} p(a_{ij} \\ | \\ \\vct{z}_i,\\vct{z}_j).\n",
    "\\end{equation*}\n",
    "It is convenient to use\n",
    "\\begin{equation*}\n",
    "  p(a_{ij}=1 \\ | \\ \\vct{z}_i,\\vct{z}_j) = \\sigma(\\vct{z}_i^T\\vct{z}_j),\n",
    "\\end{equation*}\n",
    "where $\\sigma$ is the logistic sigmoid. In order to train the model, we optimize the evidence lower bound\n",
    "\\begin{equation*}\n",
    "  \\mathcal{L} = \\Expect_{q(\\vct{Z}\\ | \\ \\vct{X},\\vct{A})}[\\log p(\\mtx{A}\\ | \\ \\mtx{Z})]-\\mathrm{D}_{\\mathrm{KL}}(q(\\mtx{Z}\\ | \\ \\mtx{X},\\mtx{A}) \\ \\| \\ p(\\mtx{Z})).\n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "60438f44-f829-4cd8-9099-11dbda0ab78a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    Implement a Graph Convolutional Network (GCN) as encoder\n",
    "    \"\"\"\n",
    "    def __init__(self, dim, num_node_features, hidden_dim=32, cached=True, bias=True, add_self_loops=True, normalize=True):\n",
    "        super().__init__()\n",
    "        self.x_conv = tg.nn.GCNConv(num_node_features, \n",
    "                                    hidden_dim, \n",
    "                                    cached=cached, \n",
    "                                    bias=bias, \n",
    "                                    add_self_loops=add_self_loops,\n",
    "                                    normalize=normalize)\n",
    "        self.mean_conv = tg.nn.GCNConv(hidden_dim, \n",
    "                                       dim, \n",
    "                                       cached=cached,\n",
    "                                       bias=bias, \n",
    "                                       add_self_loops=add_self_loops,\n",
    "                                       normalize=normalize)\n",
    "        self.var_conv = tg.nn.GCNConv(hidden_dim, \n",
    "                                      dim, \n",
    "                                      cached=cached, \n",
    "                                      bias=bias, add_self_loops=add_self_loops,\n",
    "                                      normalize=normalize)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x = data.x\n",
    "        edge_index = data.edge_index\n",
    "\n",
    "        x = self.x_conv(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "\n",
    "        mu = self.mean_conv(x, edge_index)\n",
    "        sigma = self.var_conv(x, edge_index)\n",
    "        return mu, sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "1e2060dc-6804-49eb-aa5b-0a74b568d3f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = VGAE(encoder=Encoder(10, data.num_node_features))\n",
    "#model = VGAE(encoder=VGAEconv(2, test_data.num_node_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "f8bdd17a-0950-4842-bf10-198448ba843a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def VGAE_loss(model, data):\n",
    "    return model.recon_loss(model.encode(data), data.edge_index) + model.kl_loss() / data.num_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "5952dc3e-2d6d-4070-8e68-09e827820147",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(data, model, loss_fun, num_epochs=100, verbose=True, lr=0.01, logger=lambda loss: None):\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    # optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
    "    # schedule = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, num_epochs)\n",
    "    for e in tqdm(range(num_epochs)):\n",
    "        optimizer.zero_grad()\n",
    "        loss = loss_fun(model, data)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        logger(float(loss))\n",
    "        if verbose:\n",
    "            if not e % 20:\n",
    "                print(f'epoch {e}: loss={loss.item()}')\n",
    "        # schedule.step()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "613527ab-a063-4283-bd62-5ee3b58121a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4031c1a220484d1ba10a27294bbee67a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0: loss=2.833024740219116\n",
      "epoch 20: loss=1.0688931941986084\n",
      "epoch 40: loss=0.8776754140853882\n",
      "epoch 60: loss=0.8293766379356384\n",
      "epoch 80: loss=0.8050824999809265\n",
      "epoch 100: loss=0.7938762903213501\n",
      "epoch 120: loss=0.7871164083480835\n",
      "epoch 140: loss=0.7822022438049316\n",
      "epoch 160: loss=0.7768582105636597\n",
      "epoch 180: loss=0.770989179611206\n"
     ]
    }
   ],
   "source": [
    "model = train(data, model, VGAE_loss, num_epochs=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd78c888-0043-43be-88b7-4f5ce49e77f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def VGAE_patch_embeddings(patch_data, dim=2, hidden_dim=32, num_epochs=100, decoder=None, device='cpu', lr=0.01):\n",
    "    patch_list = []\n",
    "    models = []\n",
    "    for patch in patch_data:\n",
    "        if patch.x is None:\n",
    "            patch.x = speye(patch.num_nodes)\n",
    "            print(f\"training patch with {patch.edge_index.shape[1]} edges\")   #added [i] to every patch\n",
    "            model = tg.nn.VGAE(encoder=VGAEconv(dim, patch.x.shape[1], hidden_dim=hidden_dim), decoder=decoder).to(device)\n",
    "            patch.to(device)\n",
    "\n",
    "        model = train(patch, model, VGAE_loss, num_epochs=num_epochs, lr=lr)\n",
    "        with torch.no_grad():\n",
    "            model.eval()\n",
    "            coordinates = model.encode(patch).to('cpu').numpy()\n",
    "            models.append(model)\n",
    "            patch_list.append(l2g.Patch(patch.nodes.to('cpu').numpy(), coordinates))\n",
    "    return patch_list, models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ad01511-5965-4676-8b56-dd304d2ec538",
   "metadata": {},
   "source": [
    "###  <a id='chapter3'> <font color=\"grey\">3. Visualisation </font></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24c57c17-115a-4aee-8d9f-cd69d89901e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use UMAP to visualise the graph embeddings for different days"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
